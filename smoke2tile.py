'''
Create tile plots from CMAQ-ready NetCDF files generated by SMOKE.
'''

import cPickle
import matplotlib
matplotlib.use("Agg")
import matplotlib.pyplot as plt
from matplotlib import cm, colors
from mpl_toolkits.basemap import Basemap
from mpl_toolkits.basemap import cm as bcm
from netCDF4 import Dataset
import numpy as np
from pyproj import Proj
import os
os.environ['DISPLAY'] = ':1000.0'
import shapefile
import subprocess
import sys
import time

# CONSTANTS
KG_TO_TON = 0.00110231
CATEGORY = {'010':'ElecUtil', '020':'Cogen', '030':'OilGasCmb', '040':'PetRefCmb',
            '050':'ManufInd', '052':'FoodAgProc', '060':'ServCommer', '099':'OtherFuelCmb',
            '110':'SewageTreat', '120':'Landfills', '130':'Incinerators', '140':'SoilRemed',
            '199':'OtherWasteDis', '210':'Laundering', '220':'Degreasing', '230':'CoatingsRel',
            '240':'Printing', '250':'AdhSealant', '299':'OtherCleanSurf', '310':'OilGasProd',
            '320':'PetRef', '330':'PetMarket', '399':'OtherPetProdMar', '410':'Chemical',
            '420':'FoodAg', '430':'MineralPro', '440':'MetalPro', '450':'WoodPaper',
            '460':'GlassRelated', '470':'Electronics', '499':'OtherIndProc',
            '500':'SolventEvapUnsp', '510':'ConsumProd', '520':'ArchCoatRelProc',
            '530':'PestFertil', '540':'AsphPavingRoof', '550':'Refrigerants',
            '599':'OtherSolventEvap', '610':'ResidFuelCmb', '620':'FarmOper', '630':'ConstrDemo',
            '640':'PavedRoad', '645':'UnpavedRd', '650':'FugWindDust', '660':'Fires',
            '670':'ManagBurnDisp', '680':'UtilEquip','690':'Cooking', '699':'OtherMiscProc',
            '700':'OnRdVehicleUnspec','710':'LDALightDutyPasseng', '720':'LightMedDutyTrucks',
            '722':'LDT1','723':'LDT2','724':'MDVMedDutyTrucks', '730':'HDGasTruckAll',
            '732':'LHDV1Gas','733':'LHDV2Gas','734':'MHDVGas', '736':'HHDVGas',
            '740':'HDDieselTruckAll', '742':'LHDV1Diesel', '743':'LHDV2Diesel',
            '744':'MHDVDiesel', '746':'HHDVDiesel', '750':'MCY', '760':'HDDiesleUB',
            '762':'HDGasUB', '770':'SB', '771':'SBGas', '772':'SBDiesel', '776':'OB',
            '777':'OBGas', '778':'OBMotorCoach', '779':'AllOBDiesel', '780':'MH',
            '799':'OnRdMotorVeh', '810':'Aircraft', '820':'Trains', '830':'ShipsCommBoats',
            '833':'OGV', '835':'CommHarborCraft', '840':'RecBoats', '850':'OffRdRecVeh',
            '860':'OffRdEquip', '870':'FarmEquip', '890':'FuelStorageHandling',
            '899':'OtherMobileSrc', '910':'Biogenic', '920':'Geogenic', '930':'Wildfires',
            '940':'WindblownDust', '999':'OtherNaturalSrc'}
EXT = 'png'
SC4K = False
UNIT = 'tons $d^{-1}$'
# DATA FILES
INPUT_DIR = 'input/'
OUTPUT_DIR = 'output/'
PICKLE_DIR = INPUT_DIR + 'pickles/'
PICKLED_LATLON = PICKLE_DIR + 'lons_lats.p'
PICKLED_PYFRAC = PICKLE_DIR + 'pyfractions.p'
COABDIS_SHAPES = INPUT_DIR + 'coabdis_gai_oc1_oc2_latlon_20140924/coabdis_gai_oc1_oc2_latlon_20140924'
OCEAN_SHAPE = INPUT_DIR + 'ocean_boundary_latlon/ocean_boundary_latlon'
STATE_SHAPES = INPUT_DIR + 'State4k/State4k_new'
SMOKE2TILE_TOTALS = {}

'''
import pandas as pd
PICKLED_EICGRP = PICKLE_DIR + 'eic_grouping_20141205.p'
EICGRP_CATEGORY = cPickle.load(open(PICKLED_EICGRP, "rb"))
eicgrp_fn = "./input/eic_grouping_20141205.csv"
fn = os.path.basename(eicgrp_fn).split(".")[0]
eicgrp_df = pd.read_csv(eicgrp_fn)
eicgrp_df['CAT_DESC'] = eicgrp_df.CAT_DESC.map(lambda x: x.title().replace('_', ''))
eicgrp_df['CAT_DESC'] = eicgrp_df.CAT_DESC.map(lambda x: x.replace('Ogv', 'OGV'))
eicgrp_df['CAT_DESC'] = eicgrp_df.CAT_DESC.map(lambda x: x.replace('Chc', 'CHC'))
eicgrp_dict = dict((i[0],i[1]) for i in eicgrp_df[['CAT_NUM','CAT_DESC']].drop_duplicates().values)
pickle.dump(eicgrp_dict, open('../input/pickles/' + fn + '.p', 'wb'))
'''


def df_to_nested_dict(frame):
    """ Converts a pandas dataframe into a nested dictionary.
    """
    d = {}
    for row in frame.values:
        here = d
        for elem in row[:-2]:
            if elem not in here:
                here[elem] = {}
            here = here[elem]
        here[row[-2]] = row[-1]
    return d


class AnnualInventory(object):

    """ Class that handles a pickled annual inventory to plot (rather than a
        netCDF).
    """

    def __init__(self, fin):
        self.fin = fin

    def unpickle(self):
        """ Load pickled annual emissions inventory.
        """
        invHandle = cPickle.load(open(self.fin,"rb"))
        self.df = invHandle['df']
        self.ff10_fn = invHandle['ff10']

    def split_by_eicsum(self):
        """ Load subset of annual emissions inventory by eicsum into a
            dictionary.
        """
        self.inv_eicsum = {}
        for eicsum in self.df.EICSUM.unique().tolist():
            subset = self.df[self.df. EICSUM == eicsum]
            self.inv_eicsum[eicsum] = subset


class DataFrame2Array(object):

    """ Class that handles a dataframe and converts it into a numpy
        (similiar to grid array used when plotting a netCDF).
    """

    def __init__(self, df, ff10):
        self.df = df
        self.ff10 = ff10
        self.eicsum = self.df.EICSUM.unique().tolist()[0]

    def build_array(self):
        """ Build base array for adding dataframe data to.
        """
        self.POLS = ['CO','NOX','SOX','TOG','PM','NH3']
        self.NROW = 291  # statewide 4-km domain
        self.NCOL = 321  # statewide 4-km domain
        self.grid = {}
        self.total = {}
        for pol in self.POLS:
            self.grid[pol] = np.zeros((self.NROW,self.NCOL), dtype=float)
            self.total[pol] = np.zeros((1), dtype=float)

    def split_df_by_pol(self):
        """ Splits df (already a subset of the annual inventory for a single
            eicsum) by pollutant.
        """
        self.df_by_pol = {}
        for pol in self.POLS:
            if len(self.df[self.df. POLABBREV == pol]) > 0:
                self.df_by_pol[pol] = self.df[self.df. POLABBREV == pol]
            else:
                print("\tPollutant not found:   %s" % pol)

    def fill_grid(self):
        """ Fills initialized grid array with emissions data from pandas
            dataframe. Converts dataframe to nested dictionary first for
            improved performance.
        """
        for pol in self.df_by_pol.keys():
            print("\tWorking on pollutant:  %s" % pol)
            subset = self.df_by_pol[pol]
            frame = subset.loc[:,'I_CELL':]
            d = df_to_nested_dict(frame)
            for i in d.keys():
                for j in d[i].keys():
                    ems = d[i][j]
                    self.grid[pol][int(j) - 1][int(i) - 1] = ems
                    self.total[pol] += ems

    def get_out_filename(self):
        """ Parses input FF10 filename to get output plot filename.
        """
        fn_fields = self.ff10.strip().split(".")
        domain = fn_fields[0]
        srctype = fn_fields[1]
        vinv = fn_fields[2]
        eicsum = self.eicsum  # fn_fields[3]
        byear = fn_fields[4]
        fyear = fn_fields[5]
        cepam = fn_fields[6]
        vsmk = fn_fields[7]
        # vspec = fn_fields[8]
        # ftype = fn_fields[9]

        by = "B" + byear[-2:]
        fy = "F" + fyear[-2:]
        self.eicsumn = CATEGORY[eicsum]
        self.sector = "_".join([srctype, self.eicsum, self.eicsumn])
        self.myear = by + "_" + fy
        self.inventory = cepam
        self.outname = "_".join([domain, srctype, vinv, eicsum, self.eicsumn, by, fy, cepam, vsmk])


class PlotArray(object):
    """ Variant of "plot_emissions" method within the "SmokeFile" class. Handles
        the plotting of emissions from an annual inventory dataframe (converted
        to numpy array) rather than a netCDF.
    """

    def __init__(self, arrObj):
        self.grid = arrObj.grid
        self.total = arrObj.total
        self.eicsum = arrObj.eicsum
        self.eicsumn = arrObj.eicsumn
        self.outname = arrObj.outname
        self.sector = arrObj.sector
        self.myear = arrObj.myear
        self.inventory = arrObj.inventory

    def plot_emissions(self, dpi, fig_size, basemap):
        """ Plots emissions from numpy array (converted from pandas
            dataframe of annual emissions inventory).
        """
        # Setup a plot
        fig = plt.figure(figsize=fig_size)
        plt.figtext(0.75, 0.02, "last updated: " + time.strftime("%c"), size="xx-small")

        # get grid lat/lons
        try:
            [grd_lons, grd_lats] = cPickle.load(open(PICKLED_LATLON, "rb"))
        except:
            r = shapefile.Reader(STATE_SHAPES)
            shapes = r.shapes()
            records = r.records()
            grd_lons = []
            grd_lats = []
            for record, shape in zip(records,shapes):
                grd_lons.append(shape.points[0][0])
                grd_lats.append(shape.points[0][1])

            cPickle.dump([grd_lons, grd_lats], open(PICKLED_LATLON, "wb"))

        # plot each pollutant category as a raster

        # figure out how many panels we'll need for this plot
        count = len([grp for grp in ['NOX', 'SOX', 'TOG', 'PM', 'NH3', 'CO'] if not np.all(self.grid[grp] == 0)])

        if count == 1:
            pos = 111
            fntsz = 10
        elif count == 2:
            pos = 211
            fntsz = 9
        elif count == 3:
            pos = 311
            fntsz = 8
        elif count == 3 or count == 4:
            pos = 221
            fntsz = 8
        else:
            pos = 321  # we want a 3 x 2 plot; start with position "1"
            fntsz = 7

        for grp in ['CO', 'NOX', 'SOX', 'TOG', 'PM', 'NH3']:
            if not np.all(self.grid[grp] == 0):
                ax = fig.add_subplot(pos)
                cs = basemap.pcolor(grd_lons, grd_lats, self.grid[grp], cmap=cm.jet,
                                    norm=colors.LogNorm(), latlon=True)
                basemap.readshapefile(COABDIS_SHAPES, 'GAI')
                basemap.readshapefile(OCEAN_SHAPE, 'FID')
                cbar = plt.colorbar(orientation='vertical')
                cl = plt.getp(cbar.ax, 'ymajorticklabels')
                plt.setp(cl,fontsize=fntsz)
                plt.annotate('domain total: ' + str("{0:6.2f}".format(float(self.total[grp]))),
                             xy=(.50, .95), xycoords='axes fraction', fontsize=(fntsz - 2))
                plt.title("_".join([grp, self.sector, self.myear, self.inventory]), fontsize=fntsz)
                cbar.set_label("emissions rate [" + UNIT + "]", fontsize=fntsz)
                pos += 1

        fig.savefig(OUTPUT_DIR + self.outname + "." + EXT, format=EXT.upper(), bbox_inches='tight', dpi=dpi)
        fig.clf()

        plt.close(fig)


class SmokeFile(object):

    def __init__(self, fin, basemap):
        self.fin = fin
        self.basemap = basemap
        self.source = ''
        self.date = ''
        self.inventory = ''
        self.grid = None
        self.total = {}

    def decompress(self):
        '''Decompress a gzipped input NetCDF file, if it needs it.'''
        if self.fin[-3:] == '.gz':
            subprocess.call(["gunzip", os.path.dirname(self.fin) + "/" + os.path.basename(self.fin)])
            self.fin = self.fin[:-3]

    def recompress(self):
        '''gzip up the input file when you're done'''
        subprocess.call(["gzip", os.path.dirname(self.fin) + "/" + os.path.basename(self.fin)])
        self.fin = self.fin + ".gz"

    def load_emissions(self):
        '''Open netCDF file and read data into array and then aggregate'''
        # parse file name for important info
        filename = self.fin.split('/')
        filename = filename[len(filename) - 1].split('.')

        file_type = filename[1]
        eicsum_catnum = filename[3]  # eicsum or eicsum-catgory number combination

        # to identify EIC categories groupings in a more descriptive manner
        if "_" in eicsum_catnum:
            eicsum = eicsum_catnum.split("_")[0]
            catnum = int(eicsum_catnum.split("_")[1].lstrip("c"))
            eicsumn = "_".join([eicsum, CATEGORY[eicsum], "c" + str(catnum), EICGRP_CATEGORY[catnum]])
        else:
            try:
                eicsum = eicsum_catnum
                eicsumn = "_".join([eicsum,CATEGORY[eicsum]])
            except:
                pass

        #  if a source category is given
        if filename[3] != '':
            try:
                self.source = file_type + '_' + eicsumn
            except KeyError:
                raise KeyError("Sorry, I cannot find this category %s" % eicsum_catnum)
        else:
            self.source = file_type + '_all'

        self.date = filename[5]
        self.inventory = filename[6]

        ncdf = Dataset(self.fin, 'r')

        # open data set, and start reading
        try:
            data = Dataset(self.fin,'r')
        except:
            raise IOError('Cannot open file %s' % self.fin)

        ncol = data.NCOLS
        nrow = data.NROWS

        if ncol != 320 and nrow != 291:
            raise ValueError('ncols=%s' % ncol, 'nrows=%s' % nrow, '\nThis is not the standard 4-km CA domain.\n')

        self.grid = {'CO':np.zeros((nrow,ncol), dtype=float), 'NOX':np.zeros((nrow,ncol), dtype=float),
                     'SOX':np.zeros((nrow,ncol), dtype=float), 'TOG':np.zeros((nrow,ncol), dtype=float),
                     'PM':np.zeros((nrow,ncol), dtype=float), 'NH3':np.zeros((nrow,ncol), dtype=float)}

        self.total = {'CO':np.zeros((1), dtype=float), 'NOX':np.zeros((1), dtype=float),
                      'SOX':np.zeros((1), dtype=float), 'TOG':np.zeros((1), dtype=float),
                      'PM':np.zeros((1), dtype=float), 'NH3':np.zeros((1), dtype=float)}

        nvar = data.NVARS

        count = 0
        for species, value in data.variables.iteritems():
            if str(species) != "TFLAG":
                print(str(species))
                count += 1

        # load information about each species
        [pdt_frac, sccref_frac, pmref_frac, spec_mwt, spec_pos, spec_grps] = cPickle.load(open(PICKLED_PYFRAC, "rb"))

        if count > 6:
            self.load_speciated(data, spec_grps, spec_mwt)
        elif count <= 6:
            self.load_unspeciated(data)

    def load_unspeciated(self, data):
        '''Sum unspeciated emissions'''
        for grp in ['nox', 'sox', 'tog', 'pm', 'nh3', 'co']:
            try:
                self.grid[grp.upper()][:,:] += np.sum(data.variables[grp.upper()][0:24,:,:,:], axis=(0, 1))
                self.total[grp.upper()] = np.sum(self.grid[grp.upper()][:,:])
            except KeyError:
                print("Cannot find '%s' ..." % grp.upper())

    def load_meds3_emissions(self):
        '''Load daily-total emissions from a MEDS3 file'''
        pollutants = ['CO', 'NOX', 'SOX', 'TOG', 'PM', 'NH3']
        ncol = 320
        nrow = 291
        self.grid = {'CO': np.zeros((nrow,ncol), dtype=float), 'NOX': np.zeros((nrow,ncol), dtype=float),
                     'SOX': np.zeros((nrow,ncol), dtype=float), 'TOG': np.zeros((nrow,ncol), dtype=float),
                     'PM': np.zeros((nrow,ncol), dtype=float), 'NH3': np.zeros((nrow,ncol), dtype=float)}

        self.total = {'CO': np.float64(0.0), 'NOX': np.float64(0.0),
                      'SOX': np.float64(0.0), 'TOG': np.float64(0.0),
                      'PM': np.float64(0.0), 'NH3': np.float64(0.0)}

        # loop over each line in the MEDS3 file
        f = open(self.fin, 'r')
        for line in f.xreadlines():
            col = int(line[36:39]) - 1
            row = int(line[39:42]) - 1
            # loop over each pollutant
            for i, pol in enumerate(pollutants):
                # pull the emissions value from the correct columns
                p1 = 80 + (10 * i)
                p2 = p1 + 10
                try:
                    emis = float(line[p1:p2]) * KG_TO_TON
                except:
                    emis = 0.0
                # add that emissions value to the grid and totals
                try:
                    self.grid[pol][row][col] += emis
                    self.total[pol] += emis
                except:
                    print('Error loading MEDS3 data:', str(col), str(row), pol)

        f.close()

    def load_pmeds_emissions(self):
        '''Load daily-total emissions from a PMEDS file'''
        pollutants = ['CO', 'NOX', 'SOX', 'TOG', 'PM', 'NH3']
        ncol = 320
        nrow = 291
        self.grid = {'CO': np.zeros((nrow,ncol), dtype=float), 'NOX': np.zeros((nrow,ncol), dtype=float),
                     'SOX': np.zeros((nrow,ncol), dtype=float), 'TOG': np.zeros((nrow,ncol), dtype=float),
                     'PM': np.zeros((nrow,ncol), dtype=float), 'NH3': np.zeros((nrow,ncol), dtype=float)}

        self.total = {'CO': np.float64(0.0), 'NOX': np.float64(0.0),
                      'SOX': np.float64(0.0), 'TOG': np.float64(0.0),
                      'PM': np.float64(0.0), 'NH3': np.float64(0.0)}

        # loop over each line in the MEDS3 file
        f = open(self.fin, 'r')
        for line in f.xreadlines():
            col = int(line[36:39]) - 1
            row = int(line[39:42]) - 1
            # loop over each pollutant
            for i, pol in enumerate(pollutants):
                # pull the emissions value from the correct columns
                polls = line[78:].strip()
                try:
                    emis = float(polls.split(',')[i]) * KG_TO_TON
                except:
                    emis = 0.0
                # add that emissions value to the grid and totals
                try:
                    self.grid[pol][row][col] += emis
                    self.total[pol] += emis
                except:
                    print('Error loading MEDS3 data:', str(col), str(row), pol)

        f.close()

    def load_meds3_emissions_hourly(self):
        '''Load daily-total emissions from a MEDS3 file'''
        pollutants = ['CO', 'NOX', 'SOX', 'TOG', 'PM', 'NH3']
        ncol = 320
        nrow = 291
        nhrs = 24
        self.grid = {'CO': np.zeros((nhrs,nrow,ncol), dtype=float), 'NOX': np.zeros((nhrs,nrow,ncol), dtype=float),
                     'SOX': np.zeros((nhrs,nrow,ncol), dtype=float), 'TOG': np.zeros((nhrs,nrow,ncol), dtype=float),
                     'PM': np.zeros((nhrs,nrow,ncol), dtype=float), 'NH3': np.zeros((nhrs,nrow,ncol), dtype=float)}

        self.total = {'CO': np.zeros(nhrs, dtype=float), 'NOX': np.zeros(nhrs, dtype=float),
                      'SOX': np.zeros(nhrs, dtype=float), 'TOG': np.zeros(nhrs, dtype=float),
                      'PM': np.zeros(nhrs, dtype=float), 'NH3': np.zeros(nhrs, dtype=float)}

        # loop over each line in the MEDS3 file
        f = open(self.fin, 'r')
        for line in f.xreadlines():
            col = int(line[36:39]) - 1
            row = int(line[39:42]) - 1
            bhr  = int(line[63:65])
            ehr  = int(line[65:67])
            if ehr > bhr:
                hrs = range(bhr,ehr+1)
            elif ehr == bhr:
                hrs = [bhr]
            else:
                print "\n\nWARNING: end hour is before beginning hour!\n\n"
            # loop over each pollutant
            for i, pol in enumerate(pollutants):
                # pull the emissions value from the correct columns
                p1 = 80 + (10 * i)
                p2 = p1 + 10
                try:
                    emis = float(line[p1:p2]) * KG_TO_TON
                except:
                    emis = 0.0
                # add that emissions value to the grid and totals
                try:
                    for hr in hrs:
                        self.grid[pol][hr][row][col] += emis
                        self.total[pol][hr] += emis
                except:
                    print('Error loading MEDS3 data:', str(col), str(row), pol)

        f.close()

    def load_pmeds_emissions_hourly(self):
        '''Load daily-total emissions from a PMEDS file'''
        pollutants = ['CO', 'NOX', 'SOX', 'TOG', 'PM', 'NH3']
        ncol = 320
        nrow = 291
        nhrs = 24
        self.grid = {'CO': np.zeros((nhrs,nrow,ncol), dtype=float), 'NOX': np.zeros((nhrs,nrow,ncol), dtype=float),
                     'SOX': np.zeros((nhrs,nrow,ncol), dtype=float), 'TOG': np.zeros((nhrs,nrow,ncol), dtype=float),
                     'PM': np.zeros((nhrs,nrow,ncol), dtype=float), 'NH3': np.zeros((nhrs,nrow,ncol), dtype=float)}

        self.total = {'CO': np.zeros(nhrs, dtype=float), 'NOX': np.zeros(nhrs, dtype=float),
                      'SOX': np.zeros(nhrs, dtype=float), 'TOG': np.zeros(nhrs, dtype=float),
                      'PM': np.zeros(nhrs, dtype=float), 'NH3': np.zeros(nhrs, dtype=float)}

        # loop over each line in the MEDS3 file
        f = open(self.fin, 'r')
        for line in f.xreadlines():
            col = int(line[36:39]) - 1
            row = int(line[39:42]) - 1
            bhr  = int(line[63:65])
            ehr  = int(line[65:67])
            if ehr > bhr:
                hrs = range(bhr,ehr+1)
            elif ehr == bhr:
                hrs = [bhr]
            else:
                print "\n\nWARNING: end hour is before beginning hour!\n\n"
            # loop over each pollutant
            polls = line[78:].strip()
            for i, pol in enumerate(pollutants):
                try:
                    emis = float(polls.split(',')[i]) * KG_TO_TON
                except:
                    emis = 0.0
                # add that emissions value to the grid and totals
                try:
                    for hr in hrs:
                        self.grid[pol][hr][row][col] += emis
                        self.total[pol][hr] += emis
                except:
                    print('Error loading MEDS3 data:', str(col), str(row), pol)

        f.close()

    def load_speciated(self, data, spec_grps, spec_mwt):
        '''Sum speciated emissions'''
        unfound = []

        for grp in ['nox', 'sox', 'tog', 'pm']:
            for spec in spec_grps[grp]:
                if grp == 'pm' or grp == 'tog':
                    try:
                        self.grid[grp.upper()][:,:] += (np.sum(data.variables[spec][0:24, :, :, :], axis=(0,1))
                                                        * 3600.0 * spec_mwt[str(spec)] / 1000 * KG_TO_TON)
                        self.total[grp.upper()] = np.sum(self.grid[grp.upper()][:, :])
                    except KeyError:
                        unfound.append(str(spec))
                elif grp == 'nox':
                    try:
                        self.grid['NOX'][:,:] += (np.sum(data.variables[spec][0:24,:,:,:], axis=(0, 1))
                                                  * spec_mwt['NO2'] / spec_mwt[spec] * 3600 *
                                                  spec_mwt[str(spec)] / 1000 * KG_TO_TON)
                        self.total[grp.upper()] = np.sum(self.grid[grp.upper()][:,:])
                    except KeyError:
                        unfound.append(str(spec))
                elif grp == 'sox':
                    try:
                        self.grid['SOX'][:,:] += (np.sum(data.variables[spec][0:24, :, :, :], axis=(0, 1))
                                                  * spec_mwt['SO2'] / spec_mwt[spec] * 3600 *
                                                  spec_mwt[str(spec)] / 1000 * KG_TO_TON)
                        self.total[grp.upper()] = np.sum(self.grid[grp.upper()][:, :])
                    except KeyError:
                        unfound.append(str(spec))

        try:
            self.grid['CO'][:, :] = (np.sum(data.variables['CO'][0:24, :, :, :], axis=(0, 1))
                                     * 3600.0 * spec_mwt[str('CO')] / 1000 * KG_TO_TON)
            self.total['CO'] = np.sum(self.grid['CO'][:, :])
        except:
            unfound.append('CO')

        try:
            self.grid['NH3'][:, :] = (np.sum(data.variables['NH3'][0:24, :, :, :], axis=(0, 1))
                                      * 3600.0 * spec_mwt[str('NH3')] / 1000 * KG_TO_TON)
            self.total['NH3'] = np.sum(self.grid['NH3'][:, :])
        except:
            unfound.append('NH3')

        # print all the species that were missing
        if len(unfound) > 0:
            print('Cannot find the following species:')
            for species in unfound:
                print(species)
            print('')

    def plot_link_file(self, dpi, fig_size):
        '''plot ITN Link file on top of a map of California'''
        # setup a plot
        fig = plt.figure(figsize=fig_size)
        outname = "_".join(os.path.basename(self.fin).split(".")[:-1]).replace(' ', '_')
        plt.figtext(0.75, 0.02, "last updated: " + time.strftime("%c"), size="xx-small")

        # set up projection
        plcc = Proj(proj='lcc', lat_1=30.0, lat_2=60, lat_0=37, lon_0=-120.5, rsphere=6370000.00)

        # read ITN link file
        x = []
        y = []
        f = open(self.fin, 'r')
        for line in f.xreadlines():
            vals = line.strip().split()
            anodex = float(int(vals[1]))
            anodey = float(int(vals[2]))
            bnodex = float(int(vals[4]))
            bnodey = float(int(vals[5]))
            anodex, anodey = plcc(anodex, anodey, inverse=True)
            anodex, anodey = self.basemap(anodex, anodey)
            bnodex, bnodey = self.basemap(bnodex, bnodey)
            x.append(anodex)
            x.append(bnodex)
            y.append(anodey)
            y.append(bnodey)
        f.close()

        # add data and California boundaries to plot
        ax = fig.add_subplot(111)
        self.basemap.scatter(x, y, marker='o', color='r')
        self.basemap.readshapefile(COABDIS_SHAPES, 'GAI')
        self.basemap.readshapefile(OCEAN_SHAPE, 'FID')
        plt.title(' '.join([self.source, self.date, self.inventory]), fontsize=10)

        fig.savefig(OUTPUT_DIR + outname + "." + EXT, format=EXT.upper(), bbox_inches='tight', dpi=dpi)
        fig.clf()

    def plot_emissions(self, dpi, fig_size):
        '''plots a 2D array on top of a map of California'''
        pollutants = ['CO', 'NOX', 'SOX', 'TOG', 'PM', 'NH3']
        # setup a plot
        fig = plt.figure(figsize=fig_size)
        outname = "_".join(os.path.basename(self.fin).split(".")[:-1]).replace(' ', '_')
        plt.figtext(0.75, 0.02, "last updated: " + time.strftime("%c"), size="xx-small")

        try:
            [grd_lons, grd_lats] = cPickle.load(open(PICKLED_LATLON, "rb"))
        except:
            r = shapefile.Reader(STATE_SHAPES)
            shapes = r.shapes()
            records = r.records()
            grd_lons = []
            grd_lats = []
            for record, shape in zip(records,shapes):
                grd_lons.append(shape.points[0][0])
                grd_lats.append(shape.points[0][1])

            cPickle.dump([grd_lons, grd_lats], open(PICKLED_LATLON, "wb"))

        # plot each pollutant category as a raster

        # figure out how many panels we'll need for this plot
        count = len([grp for grp in pollutants if not np.all(self.grid[grp] == 0)])

        if count == 1:
            pos = 111
            fntsz = 10
        elif count == 2:
            pos = 211
            fntsz = 9
        elif count == 3:
            pos = 311
            fntsz = 8
        elif count == 3 or count == 4:
            pos = 221
            fntsz = 8
        else:
            pos = 321  # we want a 3 x 2 plot; start with position "1"
            fntsz = 7

        for grp in pollutants:
            if not np.all(self.grid[grp] == 0):
                ax = fig.add_subplot(pos)
                cs = self.basemap.pcolor(grd_lons, grd_lats, self.grid[grp], cmap=cm.jet,
                                         norm=colors.LogNorm(), latlon=True)
                self.basemap.readshapefile(COABDIS_SHAPES, 'GAI')
                self.basemap.readshapefile(OCEAN_SHAPE, 'FID')
                cbar = plt.colorbar(orientation='vertical')
                cl = plt.getp(cbar.ax, 'ymajorticklabels')
                plt.setp(cl,fontsize=fntsz)
                plt.annotate('domain total: ' + str("{0:6.2f}".format(self.total[grp])),
                             xy=(.50, .95), xycoords='axes fraction', fontsize=(fntsz - 2))
                plt.title(' '.join([grp, self.source, self.date, self.inventory]), fontsize=fntsz)
                cbar.set_label("emissions rate [" + UNIT + "]", fontsize=fntsz)
                pos += 1

        fig.savefig(OUTPUT_DIR + outname + "." + EXT, format=EXT.upper(), bbox_inches='tight', dpi=dpi)
        fig.clf()

        plt.close(fig)

    def plot_emissions_hourly(self, dpi, fig_size):
        '''plots a 2D array on top of a map of California'''
        pollutants = ['CO', 'NOX', 'SOX', 'TOG', 'PM', 'NH3']
        OUTNAME = "_".join(os.path.basename(self.fin).split(".")[:-1]).replace(' ', '_')
        TBL_OUT = "DOMAIN_TOTALS_" + OUTNAME
        tbl_out = open(OUTPUT_DIR + TBL_OUT, "w")
        tbl_out.write(os.path.basename(self.fin) + "\n\n")
        tbl_out.write("HR")
        for pol in pollutants:
            tbl_out.write("," + pol)
        tbl_out.write("\n")

        for hr in range(24):
            outname = OUTNAME + "_hr" + str(hr).zfill(2)

            grid = {}
            total = {}
            for pol in pollutants:
                grid[pol] = self.grid[pol][hr]
                total[pol] = self.total[pol][hr]

            tbl_out.write(str(hr))
            for pol in pollutants:
                tbl_out.write("," + str(total[pol]))
            tbl_out.write("\n")

            # setup a plot
            fig = plt.figure(figsize=fig_size)
            plt.figtext(0.75, 0.02, "last updated: " + time.strftime("%c"), size="xx-small")

            try:
                [grd_lons, grd_lats] = cPickle.load(open(PICKLED_LATLON, "rb"))
            except:
                r = shapefile.Reader(STATE_SHAPES)
                shapes = r.shapes()
                records = r.records()
                grd_lons = []
                grd_lats = []
                for record, shape in zip(records,shapes):
                    grd_lons.append(shape.points[0][0])
                    grd_lats.append(shape.points[0][1])

                cPickle.dump([grd_lons, grd_lats], open(PICKLED_LATLON, "wb"))

            # plot each pollutant category as a raster

            # figure out how many panels we'll need for this plot
            count = len([grp for grp in pollutants if not np.all(grid[grp] == 0)])

            if count == 1:
                pos = 111
                fntsz = 10
            elif count == 2:
                pos = 211
                fntsz = 9
            elif count == 3:
                pos = 311
                fntsz = 8
            elif count == 3 or count == 4:
                pos = 221
                fntsz = 8
            else:
                pos = 321  # we want a 3 x 2 plot; start with position "1"
                fntsz = 7

            for grp in pollutants:
                if not np.all(grid[grp] == 0):
                    ax = fig.add_subplot(pos)
                    cs = self.basemap.pcolor(grd_lons, grd_lats, grid[grp], cmap=cm.jet,
                                             norm=colors.LogNorm(), latlon=True)
                    self.basemap.readshapefile(COABDIS_SHAPES, 'GAI')
                    self.basemap.readshapefile(OCEAN_SHAPE, 'FID')
                    cbar = plt.colorbar(orientation='vertical')
                    cl = plt.getp(cbar.ax, 'ymajorticklabels')
                    plt.setp(cl,fontsize=fntsz)
                    plt.annotate('domain total: ' + str("{0:6.2f}".format(total[grp])),
                                 xy=(.50, .95), xycoords='axes fraction', fontsize=(fntsz - 2))
                    plt.title(' '.join([grp, self.source, self.date, self.inventory]), fontsize=fntsz)
                    cbar.set_label("emissions rate [" + UNIT + "]", fontsize=fntsz)
                    pos += 1

            fig.savefig(OUTPUT_DIR + outname + "." + EXT, format=EXT.upper(), bbox_inches='tight', dpi=dpi)
            fig.clf()

            plt.close(fig)
        tbl_out.close()

    def plot_annual_inv(self, dpi, fig_size):
        ''' Calculate and plot annual emissions totals from annual inventory. '''
        # Load and split annual inventory by sector
        print("\nLoading annual inventory")
        yrInv = AnnualInventory(self.fin)
        yrInv.unpickle()
        yrInv.split_by_eicsum()

        # Save pollutant totals by sector
        print("\nPickling domain totals by eicsum and pollutant")
        inv = yrInv.df.copy()
        inv_tot = inv.groupby(['EICSUM','POLABBREV'], as_index=False)['EMS_CELL_TPD'].sum()
        inv_tot.columns = ['EICSUM','POLABBREV','EMS_DOMAIN_TPD']
        domain_totals_fn = OUTPUT_DIR + "domain_totals.csv"
        inv_tot.to_csv(domain_totals_fn, index=False)

        # Prep subset of inventory for plotting
        for eicsum in sorted(yrInv.inv_eicsum.keys()):
            print("\nProcessing:  %s  %s" % (eicsum, CATEGORY[eicsum]))

            # Convert subset dataframe to numpy array and prep output plot filename
            df2arr = DataFrame2Array(yrInv.inv_eicsum[eicsum], yrInv.ff10_fn)
            df2arr.build_array()
            df2arr.split_df_by_pol()
            df2arr.fill_grid()
            df2arr.get_out_filename()

            # Run plotting routine
            print("Generating plot")
            arrPlt = PlotArray(df2arr)
            arrPlt.plot_emissions(dpi, fig_size, self.basemap)

        # Rename domain totals csv file
        outname = df2arr.outname
        dom_tot_fout = OUTPUT_DIR + "_".join(["DOMAIN_TOTALS"] + outname.split("_")[:4] + outname.split("_")[6:]) + ".csv"
        os.rename(domain_totals_fn, dom_tot_fout)

    def print_emission_totals(self):
        '''A simple diagnostic print of the emissions totals'''
        for pol in self.total:
            print("%s\t:\t%.5f\t%s" % (pol, self.total[pol], UNIT))

    def reduce_grid_size(self, grd, mult):
        """approximately scaling grid size for plotting"""
        new_grd = []
        # loop through each row
        for r in xrange(len(grd) - 1):
            new_row = []

            # loop over each collumn
            for c in xrange(len(grd[r]) - 1):
                diff_r = grd[r + 1][0] - grd[r][0]
                diff_c = grd[r][c + 1] - grd[r][c]
                for m2 in xrange(mult):
                    new_row.append(grd[r][c] + m2 * float(diff_c / mult))
            # add last column
            for m2 in xrange(mult):
                new_row.append(grd[r][-1] + m2 * float(diff_c / mult))

            new_grd.append(new_row)
            # add new rows
            for m1 in xrange(1, mult):
                newest_row = []
                for val in new_row:
                    newest_row.append(val + m1 * float(diff_r / mult))
                new_grd.append(newest_row)

        # add last row
        for m1 in xrange(mult, 2 * mult):
            newest_row = []
            for val in new_row:
                newest_row.append(val + m1 * float(diff_r / mult))
            new_grd.append(newest_row)

        return np.array(new_grd)

    def save_totals(self):
        ''' Save totals written to plots for QA purposes.
        '''
        SMOKE2TILE_TOTALS[self.fin] = {}
        for grp in ['NOX', 'SOX', 'TOG', 'PM', 'NH3', 'CO']:
            SMOKE2TILE_TOTALS[self.fin][grp] = float(self.total[grp])


def split_nc_files_hourly(files):
    """Split all input NetCDF files from daily to hourly."""
    new_files = []

    # loop through all given input files
    for i in xrange(len(files)):
        # if necessary, unzip them
        if files[i][-7:] == '.ncf.gz':
            subprocess.call(["gunzip", os.path.dirname(files[i]) + "/" + os.path.basename(files[i])])
            files[i] = files[i][:-3]
        # if it is truly a NetCDF file, split it up by hours
        if files[i][-4:] == '.ncf':
            for hr in xrange(25):
                new_filepath = files[i][:-4] + '_hr' + str(hr) + '.ncf'
                subprocess.call(['ncks', '-d', 'TSTEP,' + str(hr) + ',' + str(hr), files[i], new_filepath])
                new_files.append(new_filepath)

    return files + new_files


def usage():
    print('\nPurpose:\n\nCreate tile plots from CMAQ-ready NetCDF files generated by SMOKE.')
    print('This script is only optimized for data plotted within CA.\n')
    print('Usage:\n\npython smoke2tile.py -[a|b|e|h|t|x|hr|mhr|phr|itn|#] /path/2/files')
    print('(e.g.) python smoke2tile.py -e /aa/jstilley/SMOKE_runs/*.ncf*\n')
    print('Flags:\n\n-e\tCreate plots of NetCDF emisions files (DEFAULT)')
    print('-a\tCreate plots of annual gridded totals (pickled annual gridded inventory file, not netCDF).')
    print('-hr\tHelper to the `-e` flag: plot each hour in a NetCDF file.')
    print('-m\tCreate plots of MEDS3 emissions files')
    print('-mhr\tCreate hourly plots of MEDS3 emissions files')
    print('-p\tCreate plots of pseudo-MEDS emissions files')
    print('-phr\tCreate hourly plots of pseudo-MEDS emissions files')
    print('-itn\tCreate plots of ITN link files')
    print('-t\tPrint simple totals of emissions')
    print('-h\tShow help menu.')
    print('-x\tCreate high res plots (WARNING: VERY SLOW).')
    print('\tPass pickled annual inventory dataframe path as an argument.')
    print('-1000\tCreate plots for 1km grids.')
    print('-250\tCreate plots for 250m grids.\n')
    print('\tTitle Text')
    print('-c:Your_Custom_Title_Text')
    print('\tAdd custom title text to your plots (no spaces).\n')
    print('\tBounding Box')
    print('-b:33.3,-118.2,34.0,-117.3')
    print('\tPlot using a new bounding box (say, to plot just LA county).\n')
    exit()


def main():
    # Normal Quality Images (fast to produce)
    dpi = 300
    quality = 'c'
    fig_size = (11, 8.5)

    # Bounding Box for plots
    lllat, lllon, urlat, urlon = (32.25, -124.55, 42.0, -113.0)  # Full California
    # lllat, lllon, urlat, urlon = (33.3, -118.2, 34.0, -117.3)  # Orange County
    # lllat, lllon, urlat, urlon = (33.6, -119.0, 34.9, -117.5)  # LA County
    # lllat, lllon, urlat, urlon = (33.6, -119.5, 35.1, -117.5)  # Ventura County

    # parse command line for flags and input NetCDF files
    run_type = '-e'
    grid_size = 4000
    a = 1
    files = []
    title_txt = ''
    split_hourly = False

    # parse commandline flags
    while(a < len(sys.argv)):
        if sys.argv[a][0] == '-':
            if sys.argv[a] in ['-a', '-e', '-m', '-p', '-t', '-mhr', '-phr', '-itn']:
                run_type = sys.argv[a]
            elif sys.argv[a] == '-hr':
                split_hourly = True
            elif sys.argv[a] == '-x':
                # High Quality Images (very slow to produce)
                dpi = 600
                quality = 'f'
            elif sys.argv[a] in ['-250', '-1000', '-2000', '-4000', '-12000']:
                grid_size = -1 * int(sys.argv[a])
            elif sys.argv[a][1] == 'c':
                title_txt = sys.argv[a][3:]
            elif sys.argv[a][1] == 'b':
                lllat,lllon,urlat,urlon = [float(n) for n in sys.argv[a][3:].split(',')]
            else:
                usage()
        else:  # all non-flags are presumed to be files
            files.append(sys.argv[a])
        a += 1

    # verify the user gave reasonable input
    if a <= 1:
        usage()
    elif len(files) < 1:
        raise UnboundLocalError('No input files found.')

    if split_hourly:
        files = split_nc_files_hourly(files)

    # initiate a map (MM5 Sphere LCC projection)
    basemap = Basemap(llcrnrlat=lllat, llcrnrlon=lllon, urcrnrlat=urlat, urcrnrlon=urlon,
                      projection='lcc', lat_1=30.0, lat_2=60, lat_0=37, lon_0=-120.5,
                      rsphere=6370000.00, resolution=quality)

    # loop through input files and create outputs
    for fin in files:
        print('\nProcessing: ' + str(os.path.basename(fin)))
        sf = SmokeFile(fin, basemap)

        # optional outputs, defined by the user
        if run_type == '-a':
            sf.plot_annual_inv(dpi, fig_size)
        elif run_type == '-e':
            sf.decompress()
            sf.load_emissions()
            sf.plot_emissions(dpi, fig_size)
            sf.save_totals()
            sf.recompress()
        elif run_type == '-m':
            sf.decompress()
            sf.load_meds3_emissions()
            sf.plot_emissions(dpi, fig_size)
            #sf.recompress()
        elif run_type == '-p':
            sf.decompress()
            sf.load_pmeds_emissions()
            sf.plot_emissions(dpi, fig_size)
            sf.recompress()
        elif run_type == '-mhr':
            sf.decompress()
            sf.load_meds3_emissions_hourly()
            sf.plot_emissions_hourly(dpi, fig_size)
            #sf.recompress()
        elif run_type == '-phr':
            sf.decompress()
            sf.load_pmeds_emissions_hourly()
            sf.plot_emissions_hourly(dpi, fig_size)
            #sf.recompress()
        elif run_type == '-itn':
            sf.plot_link_file(dpi, fig_size)
        elif run_type == '-t':
            sf.decompress()
            sf.load_emissions()
            sf.print_emission_totals()
            sf.recompress()

    if run_type == '-e':
        cPickle.dump(SMOKE2TILE_TOTALS, open('./output/' + "SMOKE2TILE_TOTALS" + '.p', 'wb'))


if __name__ == "__main__":
    main()
